{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys,os\n",
    "sys.path.append('../')   \n",
    "import numpy as np\n",
    "from model.erroneousPreference import erroneousPreference\n",
    "from utility import  paramz\n",
    "from kernel import RBF\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from inference import laplace_generic as LAP\n",
    "from bayesopt import create_comparison_data, BayesOpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two variables bounded between 0.1-20 and 1-8\n",
    "k_bounds, d_bounds = (0.1, 20.), (1., 8.)\n",
    "bounds = np.vstack([k_bounds, d_bounds])\n",
    "# True values are 10 and 2\n",
    "k_true, d_true = 10., 2.\n",
    "true_vector = [k_true, d_true]\n",
    "# We will try to find the true values with Bayesian optimization preference learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates data of 5 comparisons to initalize the GP.\n",
    "# When creating this data, we assume the user always selects the alternative that has\n",
    "# closer L-2 distance to the true_vector\n",
    "n_samp = 5\n",
    "data = {}\n",
    "data[\"X\"] , data[\"Pairs\"] = create_comparison_data(bounds, true_vector, n_samp)\n",
    "\n",
    "# data[\"X\"] contains the vector values (k and d) for each compared alternative\n",
    "# data[\"Pairs\"] shows the pair wise comparisons. The values here shows the index of X compared. The index showed first is the one preferred/selected\n",
    "# For example if it shows [7,4] it means X[7] and X[4] are compared and X[7] were preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our GP model\n",
    "\n",
    "# define kernel and hyperparams\n",
    "Kernel = RBF\n",
    "\n",
    "#kernel parameter dictionary\n",
    "params={'lengthscale': {'value':1.5*np.ones(data[\"X\"].shape[1], float), \n",
    "                        'range': bounds,\n",
    "                        'transform': paramz.logexp()},\n",
    "        'variance': {'value':np.array([1.0]), \n",
    "                        'range':np.vstack([[0.01, 10.01]]),\n",
    "                        'transform': paramz.logexp()}#variance not used in exactPreference\n",
    "          }\n",
    "\n",
    "\n",
    "# Ignore the ones below\n",
    "\n",
    "#model.optimize_hyperparams(num_restarts=2)\n",
    "#model.sample(nsamples=10000, tune=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize parameters using Laplace Method \n",
    "\n",
    "Below is our 10 iterations for pairwise learning.\n",
    "\n",
    "- `infer` object optimizes the hyperparameters of GP for the data and we also use it to create predictions with GP\n",
    "- `BayesOpt` class proposes next X to try with BayesOpt using Expected Improvement Acquisition function (see inside this class in `bayesopt/bayesopt.py` to learn more)\n",
    "- We choose the option that has the smaller l2 distance to true_vector\n",
    "- Then we update the `infer` class with the new comparison added to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively find the optimal point\n",
    "n_comparisons = 10\n",
    "\n",
    "model = erroneousPreference(data,Kernel,params)\n",
    "infer = LAP.inference_laplace(data, \n",
    "                              RBF, \n",
    "                              model.params,\n",
    "                              model._log_likelihood,\n",
    "                              model._grad_loglikelihood,\n",
    "                              model._hess_loglikelihood)\n",
    "\n",
    "infer.optimize(recompute_grad_hessian_at_params_change=True,num_restarts=2)\n",
    "bo = BayesOpt(infer, bounds)\n",
    "\n",
    "for i in range(n_comparisons):\n",
    "    new_data = bo.propose_next(10,5).flatten()\n",
    "    current_max_X = bo.x_max\n",
    "    current_max_ind = bo.x_max_ind\n",
    "    \n",
    "    left_pref = norm(new_data - np.array(true_vector)) < norm(current_max_X - np.array(true_vector))    \n",
    "    print(f\"Current max: {current_max_X}; Compared: {new_data}\")\n",
    "    \n",
    "    Pairs, X = data[\"Pairs\"], data[\"X\"]\n",
    "    \n",
    "    X = np.vstack([X, new_data])\n",
    "    print(X.shape)\n",
    "    new_ind = len(X) - 1\n",
    "    preferred_index = np.array([new_ind, current_max_ind]) if left_pref else np.array([current_max_ind, new_ind])\n",
    "    \n",
    "    print(f\"Preferred: {X[preferred_index[0]]}\")\n",
    "    \n",
    "    Pairs = np.vstack([Pairs, preferred_index])\n",
    "    data = {}\n",
    "    data[\"Pairs\"], data[\"X\"] = Pairs, X\n",
    "\n",
    "    model = erroneousPreference(data,Kernel,params)\n",
    "    infer = LAP.inference_laplace(data, \n",
    "                              RBF, \n",
    "                              model.params,\n",
    "                              model._log_likelihood,\n",
    "                              model._grad_loglikelihood,\n",
    "                              model._hess_loglikelihood)\n",
    "\n",
    "    infer.optimize(recompute_grad_hessian_at_params_change=True,num_restarts=2)\n",
    "    bo = BayesOpt(infer, bounds)\n",
    "\n",
    "print(f\"Optimal point: {bo.x_max}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
